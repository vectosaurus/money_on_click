{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:14:38.519828Z",
     "start_time": "2020-05-29T10:14:38.321635Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For data preparation, I am going to \n",
    "- read all the files, \n",
    "- sort them by timestamp, \n",
    "- merge the corresponding label and sensor files\n",
    "- drop rows with missing values\n",
    "- add a sensor type to the dataset\n",
    "- combine data from all sensors, sort by timestamp and then delete timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:25.131691Z",
     "start_time": "2020-05-31T19:28:24.587986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "a_sensor_data = pd.read_csv(\"Downloads/Phone shake detection assignmen/a.sensor.csv\")\n",
    "a_labels = pd.read_csv(\"Downloads/Phone shake detection assignmen/a.lbl.csv\")\n",
    "\n",
    "p_sensor_data = pd.read_csv(\"Downloads/Phone shake detection assignmen/p.sensor.csv\")\n",
    "p_labels = pd.read_csv(\"Downloads/Phone shake detection assignmen/p.lbl.csv\")\n",
    "\n",
    "\n",
    "m_sensor_data = pd.read_csv(\"Downloads/Phone shake detection assignmen/m.sensor.csv\")\n",
    "m_labels = pd.read_csv(\"Downloads/Phone shake detection assignmen/m.lbl.csv\")\n",
    "\n",
    "# sort the files by time\n",
    "a_sensor_data.sort_values('timestamp(ms)', axis=0, inplace=True)\n",
    "a_labels.sort_values('timestamp(ms)', axis=0, inplace=True)\n",
    "p_sensor_data.sort_values('timestamp(ms)', axis=0, inplace=True)\n",
    "p_labels.sort_values('timestamp(ms)', axis=0, inplace=True)\n",
    "m_sensor_data.sort_values('timestamp(ms)', axis=0, inplace=True)\n",
    "m_labels.sort_values('timestamp(ms)', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:26.571747Z",
     "start_time": "2020-05-31T19:28:25.136060Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add the labels to the sensor file. \n",
    "# assuming m is greater than k, if label at timestamp t_k is 1 and is zero at the timestamp t_m, then the labels for all the sensor data lying between timestamps t_k and t_m will be 1\n",
    "\n",
    "def add_labels(sensor_data, label_data):\n",
    "    sensor_data['label'] = np.nan\n",
    "    for i in range(label_data.shape[0] - 1):\n",
    "        index = sensor_data[(sensor_data['timestamp(ms)'] >= label_data.iloc[i, 0]) & (\n",
    "                sensor_data['timestamp(ms)'] <= label_data.iloc[i + 1, 0])].index.tolist()\n",
    "        sensor_data.loc[sensor_data.index[index], 'label'] = label_data.iloc[i, 1]\n",
    "    \n",
    "    return sensor_data\n",
    "\n",
    "a_sensor_data = add_labels(a_sensor_data, a_labels)\n",
    "p_sensor_data = add_labels(p_sensor_data, p_labels)\n",
    "m_sensor_data = add_labels(m_sensor_data, m_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:26.593567Z",
     "start_time": "2020-05-31T19:28:26.575544Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "a_sensor_data.dropna(axis=0, how='any', inplace=True)\n",
    "p_sensor_data.dropna(axis=0, how='any', inplace=True)\n",
    "m_sensor_data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:26.601625Z",
     "start_time": "2020-05-31T19:28:26.595550Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add a sensor type to the dataset\n",
    "a_sensor_data['sensor_type'] = 'a'\n",
    "p_sensor_data['sensor_type'] = 'p'\n",
    "m_sensor_data['sensor_type'] = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:26.613404Z",
     "start_time": "2020-05-31T19:28:26.604180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# rearrange columns\n",
    "column_order = ['timestamp(ms)', 'acceleration_x(g)', 'acceleration_y(g)', 'acceleration_z(g)', 'roll(rad)', 'pitch(rad)', 'yaw(rad)', 'angular_velocity_x(rad/sec)', 'angular_velocity_y(rad/sec)', 'angular_velocity_z(rad/sec)', 'sensor_type', 'label']\n",
    "a_sensor_data = a_sensor_data[column_order]\n",
    "p_sensor_data = p_sensor_data[column_order]\n",
    "m_sensor_data = m_sensor_data[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:26.649928Z",
     "start_time": "2020-05-31T19:28:26.617603Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# combine data, sort by timestamps, and delete timestamps\n",
    "phone_shake_data = pd.concat([a_sensor_data, p_sensor_data, m_sensor_data], ignore_index=True)\n",
    "phone_shake_data.sort_values('timestamp(ms)', inplace=True)\n",
    "phone_shake_data.reset_index(inplace=True)\n",
    "phone_shake_data.drop([\"index\", 'timestamp(ms)'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check the number of ones and zeros in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:26.666523Z",
     "start_time": "2020-05-31T19:28:26.652328Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    84386\n",
       "0.0     2548\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is an imbalanced dataset the ratio of 0 and 1 is about 1:33. This is some imbalance in the dataset. We might have to fix this when we start the modeling process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check for outliers\n",
    "\n",
    "I am going to use z-scores to evaluate the data. If any data point has a z-score more than 3 or less than -3, I am going to flag it as an outlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:26.967593Z",
     "start_time": "2020-05-31T19:28:26.668870Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records that has atleast one outlier value:  16444\n"
     ]
    }
   ],
   "source": [
    "# lets check for outliers in our data\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "z = np.abs(stats.zscore(phone_shake_data[numeric_cols]))\n",
    "threshold = 3\n",
    "rows, cols = np.where(z > threshold)\n",
    "phone_shake_data[numeric_cols].values[rows, cols]\n",
    "phone_shake_data[numeric_cols].iloc[rows[0], cols[0]]\n",
    "print(\"Number of records that has atleast one outlier value: \", len(rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I kept the threshold at three standard deviations as it accounts for 99% of data on a normal distribution. People can select different value as their thresholds. But since this is sensor data and these accelerations and velocities may be true, I don't want to be too strict with outlier treatment. \n",
    "\n",
    "Going by z-scores, we will have issues with about 16k of our records which is about 20 percent of our data. That's a lot. I can't just delete these records straight away. \n",
    "\n",
    "And also, since this is an imbalanced dataset, I want to see how many zeros we will be losing if we simply dropped the outliers. Lets check how many of these outliers are labeled as ones and how many as zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.024262Z",
     "start_time": "2020-05-31T19:28:26.970357Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of zeros in the outliers:  72.0\n"
     ]
    }
   ],
   "source": [
    "# caclulate percentage of zeros in the outliers\n",
    "num_zeros_in_dataset = (1-phone_shake_data['label'].mean())*phone_shake_data.shape[0]\n",
    "num_zeros_in_outliers = len(set(rows)) - phone_shake_data.values[list(set(rows)), -1].sum()\n",
    "print(\"Percentage of zeros in the outliers: \", str(100*round(num_zeros_in_outliers/num_zeros_in_dataset, 2))[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a large percentage of our zeros. If we were to drop our outliers, we will loose very valuable data. One more thing to note here is that these outliers have became even more useful for us. \n",
    "\n",
    "In fact, I am going to treat them as valuable data points rather than outliers. To do that I am adding a flag column. If a row has even one value that is an outlier in its column, I am going to flag it. \n",
    "\n",
    "But before I do that, there is one more thing I want to look at it. Many of the rows that were flagged to have outliers had outliers in multiple varaibles. I want to see if there is a relation between the number of outliers in a row and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.041653Z",
     "start_time": "2020-05-31T19:28:27.026406Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 44, 46, 65]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cntr = Counter(rows)\n",
    "rev_cntr = {}\n",
    "for k in dict(cntr):\n",
    "    if cntr[k] in rev_cntr:\n",
    "        rev_cntr[cntr[k]].append(k)\n",
    "    else:\n",
    "        rev_cntr[cntr[k]] = [k]\n",
    "\n",
    "rev_cntr[4][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `cntr` dictionary tells me how many outliers the rows have. The `rev_cntr` is reverse dictionary that tells me which row indexes have `k` number of outliers. For example `rev_cntr[4]` stores values `[0,2,44,46,...]`. That means the rows with index `0`, `2`, etc. have four outliers. Similarly for `rev_cntr[3]`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.065004Z",
     "start_time": "2020-05-31T19:28:27.043722Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num outliers in a row     Num rows having that number of outliers       Percentage of ones\n",
      "1                         3760                                          86.99468085106383        \n",
      "2                         2183                                          78.74484654145671        \n",
      "3                         1094                                          70.018281535649          \n",
      "4                         600                                           57.666666666666664       \n",
      "5                         339                                           43.657817109144545       \n",
      "6                         126                                           27.77777777777778        \n",
      "7                         23                                            4.3478260869565215       \n",
      "8                         3                                             0.0                      \n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "rev_cntr = collections.OrderedDict(sorted(rev_cntr.items()))\n",
    "print('Num outliers in a row', '    Num rows having that number of outliers', '      Percentage of ones')\n",
    "for each_key in rev_cntr:\n",
    "    er = phone_shake_data.loc[rev_cntr[each_key], 'label'].mean()\n",
    "    print(\"{0: <25} {1: <45} {2: <25}\".format(each_key, len(rev_cntr[each_key]), 100*er))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The population drops as the number of outliers in a row increases. But the percentage of ones also start dropping heavily with each additional outlier. So instead of simply adding a binary flag, I am going to use this count information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.094640Z",
     "start_time": "2020-05-31T19:28:27.067794Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phone_shake_data.loc[:, 'outlier_counts'] = 0\n",
    "for each_key in rev_cntr:\n",
    "    phone_shake_data.loc[rev_cntr[each_key], 'outlier_counts'] = each_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Taking aggregates by `sensor_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.114106Z",
     "start_time": "2020-05-31T19:28:27.096739Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    60660\n",
       "m    21279\n",
       "a     4995\n",
       "Name: sensor_type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupwise counts. Just to see how much data we got from each sensor.\n",
    "phone_shake_data['sensor_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.128041Z",
     "start_time": "2020-05-31T19:28:27.116492Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sensor_type\n",
       "a    0.986186\n",
       "m    0.945862\n",
       "p    0.978124\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check groupwise event rate\n",
    "phone_shake_data.groupby('sensor_type')['label'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All the sensor types have an imbalanced distribution of zeros and ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Checking for high correlation within the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.171251Z",
     "start_time": "2020-05-31T19:28:27.129882Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_x(g)</th>\n",
       "      <th>acceleration_y(g)</th>\n",
       "      <th>acceleration_z(g)</th>\n",
       "      <th>roll(rad)</th>\n",
       "      <th>pitch(rad)</th>\n",
       "      <th>yaw(rad)</th>\n",
       "      <th>angular_velocity_x(rad/sec)</th>\n",
       "      <th>angular_velocity_y(rad/sec)</th>\n",
       "      <th>angular_velocity_z(rad/sec)</th>\n",
       "      <th>label</th>\n",
       "      <th>outlier_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acceleration_x(g)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052140</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>-0.031733</td>\n",
       "      <td>-0.069623</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>-0.069050</td>\n",
       "      <td>-0.069050</td>\n",
       "      <td>0.110037</td>\n",
       "      <td>0.068899</td>\n",
       "      <td>-0.158333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration_y(g)</th>\n",
       "      <td>-0.052140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>0.115318</td>\n",
       "      <td>0.219196</td>\n",
       "      <td>-0.044758</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>0.058232</td>\n",
       "      <td>-0.286008</td>\n",
       "      <td>0.465782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration_z(g)</th>\n",
       "      <td>-0.016647</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006351</td>\n",
       "      <td>-0.018357</td>\n",
       "      <td>0.017445</td>\n",
       "      <td>-0.108362</td>\n",
       "      <td>-0.108362</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.060044</td>\n",
       "      <td>-0.049836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roll(rad)</th>\n",
       "      <td>-0.031733</td>\n",
       "      <td>0.115318</td>\n",
       "      <td>-0.006351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.250398</td>\n",
       "      <td>-0.074876</td>\n",
       "      <td>-0.000929</td>\n",
       "      <td>-0.000929</td>\n",
       "      <td>-0.013593</td>\n",
       "      <td>-0.055336</td>\n",
       "      <td>0.097269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pitch(rad)</th>\n",
       "      <td>-0.069623</td>\n",
       "      <td>0.219196</td>\n",
       "      <td>-0.018357</td>\n",
       "      <td>-0.250398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095816</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>-0.015275</td>\n",
       "      <td>-0.060180</td>\n",
       "      <td>0.027842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yaw(rad)</th>\n",
       "      <td>0.038151</td>\n",
       "      <td>-0.044758</td>\n",
       "      <td>0.017445</td>\n",
       "      <td>-0.074876</td>\n",
       "      <td>0.095816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>-0.008461</td>\n",
       "      <td>0.074939</td>\n",
       "      <td>-0.105644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_x(rad/sec)</th>\n",
       "      <td>-0.069050</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>-0.108362</td>\n",
       "      <td>-0.000929</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.137175</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_y(rad/sec)</th>\n",
       "      <td>-0.069050</td>\n",
       "      <td>-0.093788</td>\n",
       "      <td>-0.108362</td>\n",
       "      <td>-0.000929</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.137175</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angular_velocity_z(rad/sec)</th>\n",
       "      <td>0.110037</td>\n",
       "      <td>0.058232</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>-0.013593</td>\n",
       "      <td>-0.015275</td>\n",
       "      <td>-0.008461</td>\n",
       "      <td>-0.137175</td>\n",
       "      <td>-0.137175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037306</td>\n",
       "      <td>0.004935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0.068899</td>\n",
       "      <td>-0.286008</td>\n",
       "      <td>0.060044</td>\n",
       "      <td>-0.055336</td>\n",
       "      <td>-0.060180</td>\n",
       "      <td>0.074939</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>-0.037306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.446593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlier_counts</th>\n",
       "      <td>-0.158333</td>\n",
       "      <td>0.465782</td>\n",
       "      <td>-0.049836</td>\n",
       "      <td>0.097269</td>\n",
       "      <td>0.027842</td>\n",
       "      <td>-0.105644</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>-0.446593</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acceleration_x(g)  acceleration_y(g)  \\\n",
       "acceleration_x(g)                     1.000000          -0.052140   \n",
       "acceleration_y(g)                    -0.052140           1.000000   \n",
       "acceleration_z(g)                    -0.016647           0.018931   \n",
       "roll(rad)                            -0.031733           0.115318   \n",
       "pitch(rad)                           -0.069623           0.219196   \n",
       "yaw(rad)                              0.038151          -0.044758   \n",
       "angular_velocity_x(rad/sec)          -0.069050          -0.093788   \n",
       "angular_velocity_y(rad/sec)          -0.069050          -0.093788   \n",
       "angular_velocity_z(rad/sec)           0.110037           0.058232   \n",
       "label                                 0.068899          -0.286008   \n",
       "outlier_counts                       -0.158333           0.465782   \n",
       "\n",
       "                             acceleration_z(g)  roll(rad)  pitch(rad)  \\\n",
       "acceleration_x(g)                    -0.016647  -0.031733   -0.069623   \n",
       "acceleration_y(g)                     0.018931   0.115318    0.219196   \n",
       "acceleration_z(g)                     1.000000  -0.006351   -0.018357   \n",
       "roll(rad)                            -0.006351   1.000000   -0.250398   \n",
       "pitch(rad)                           -0.018357  -0.250398    1.000000   \n",
       "yaw(rad)                              0.017445  -0.074876    0.095816   \n",
       "angular_velocity_x(rad/sec)          -0.108362  -0.000929    0.008207   \n",
       "angular_velocity_y(rad/sec)          -0.108362  -0.000929    0.008207   \n",
       "angular_velocity_z(rad/sec)           0.007924  -0.013593   -0.015275   \n",
       "label                                 0.060044  -0.055336   -0.060180   \n",
       "outlier_counts                       -0.049836   0.097269    0.027842   \n",
       "\n",
       "                             yaw(rad)  angular_velocity_x(rad/sec)  \\\n",
       "acceleration_x(g)            0.038151                    -0.069050   \n",
       "acceleration_y(g)           -0.044758                    -0.093788   \n",
       "acceleration_z(g)            0.017445                    -0.108362   \n",
       "roll(rad)                   -0.074876                    -0.000929   \n",
       "pitch(rad)                   0.095816                     0.008207   \n",
       "yaw(rad)                     1.000000                    -0.000327   \n",
       "angular_velocity_x(rad/sec) -0.000327                     1.000000   \n",
       "angular_velocity_y(rad/sec) -0.000327                     1.000000   \n",
       "angular_velocity_z(rad/sec) -0.008461                    -0.137175   \n",
       "label                        0.074939                     0.017399   \n",
       "outlier_counts              -0.105644                     0.000717   \n",
       "\n",
       "                             angular_velocity_y(rad/sec)  \\\n",
       "acceleration_x(g)                              -0.069050   \n",
       "acceleration_y(g)                              -0.093788   \n",
       "acceleration_z(g)                              -0.108362   \n",
       "roll(rad)                                      -0.000929   \n",
       "pitch(rad)                                      0.008207   \n",
       "yaw(rad)                                       -0.000327   \n",
       "angular_velocity_x(rad/sec)                     1.000000   \n",
       "angular_velocity_y(rad/sec)                     1.000000   \n",
       "angular_velocity_z(rad/sec)                    -0.137175   \n",
       "label                                           0.017399   \n",
       "outlier_counts                                  0.000717   \n",
       "\n",
       "                             angular_velocity_z(rad/sec)     label  \\\n",
       "acceleration_x(g)                               0.110037  0.068899   \n",
       "acceleration_y(g)                               0.058232 -0.286008   \n",
       "acceleration_z(g)                               0.007924  0.060044   \n",
       "roll(rad)                                      -0.013593 -0.055336   \n",
       "pitch(rad)                                     -0.015275 -0.060180   \n",
       "yaw(rad)                                       -0.008461  0.074939   \n",
       "angular_velocity_x(rad/sec)                    -0.137175  0.017399   \n",
       "angular_velocity_y(rad/sec)                    -0.137175  0.017399   \n",
       "angular_velocity_z(rad/sec)                     1.000000 -0.037306   \n",
       "label                                          -0.037306  1.000000   \n",
       "outlier_counts                                  0.004935 -0.446593   \n",
       "\n",
       "                             outlier_counts  \n",
       "acceleration_x(g)                 -0.158333  \n",
       "acceleration_y(g)                  0.465782  \n",
       "acceleration_z(g)                 -0.049836  \n",
       "roll(rad)                          0.097269  \n",
       "pitch(rad)                         0.027842  \n",
       "yaw(rad)                          -0.105644  \n",
       "angular_velocity_x(rad/sec)        0.000717  \n",
       "angular_velocity_y(rad/sec)        0.000717  \n",
       "angular_velocity_z(rad/sec)        0.004935  \n",
       "label                             -0.446593  \n",
       "outlier_counts                     1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correlations. Since the features are angular velocities and acc in perpendicular directions, I don't expect to see high correlation between features\n",
    "phone_shake_data.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a little strange. I didn't expect to see any significant correlation. But `angular_velocity_x(rad/sec)`\tand `angular_velocity_y(rad/sec)` have a correlation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.188162Z",
     "start_time": "2020-05-31T19:28:27.173506Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(phone_shake_data['angular_velocity_x(rad/sec)'] - phone_shake_data['angular_velocity_y(rad/sec)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So those two columns are exactly the same. I checked the original files. Those two columns are same. I am going to drop `angular_velocity_y(rad/sec)` from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.197107Z",
     "start_time": "2020-05-31T19:28:27.190409Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phone_shake_data.drop('angular_velocity_y(rad/sec)', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Comparing mean and distribution of the numeric features by `label`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now lets check how the mean of the variables vary across the ones and zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.225302Z",
     "start_time": "2020-05-31T19:28:27.200232Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_x(g)</th>\n",
       "      <th>acceleration_y(g)</th>\n",
       "      <th>acceleration_z(g)</th>\n",
       "      <th>roll(rad)</th>\n",
       "      <th>pitch(rad)</th>\n",
       "      <th>yaw(rad)</th>\n",
       "      <th>angular_velocity_x(rad/sec)</th>\n",
       "      <th>angular_velocity_z(rad/sec)</th>\n",
       "      <th>outlier_counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>-0.195617</td>\n",
       "      <td>0.552796</td>\n",
       "      <td>-0.082712</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.078071</td>\n",
       "      <td>-0.156965</td>\n",
       "      <td>-0.096869</td>\n",
       "      <td>0.349567</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-0.031582</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>-0.067346</td>\n",
       "      <td>-0.073827</td>\n",
       "      <td>0.680466</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>-0.010356</td>\n",
       "      <td>0.134477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acceleration_x(g)  acceleration_y(g)  acceleration_z(g)  roll(rad)  \\\n",
       "label                                                                       \n",
       "0.0            -0.195617           0.552796          -0.082712   0.101988   \n",
       "1.0            -0.031582           0.022265           0.012478  -0.067346   \n",
       "\n",
       "       pitch(rad)  yaw(rad)  angular_velocity_x(rad/sec)  \\\n",
       "label                                                      \n",
       "0.0      0.078071 -0.156965                    -0.096869   \n",
       "1.0     -0.073827  0.680466                     0.007036   \n",
       "\n",
       "       angular_velocity_z(rad/sec)  outlier_counts  \n",
       "label                                               \n",
       "0.0                       0.349567        2.000000  \n",
       "1.0                      -0.010356        0.134477  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.groupby('label').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By the looks of it, many variables have very different means across the labels. We can perform a t-test to verify if the sample means of variables in the two groups are same. \n",
    "\n",
    "For t-tests we assume homogeneity of variance and normality of distributions. Lets check if these assumptions hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.252888Z",
     "start_time": "2020-05-31T19:28:27.227183Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_x(g)</th>\n",
       "      <th>acceleration_y(g)</th>\n",
       "      <th>acceleration_z(g)</th>\n",
       "      <th>roll(rad)</th>\n",
       "      <th>pitch(rad)</th>\n",
       "      <th>yaw(rad)</th>\n",
       "      <th>angular_velocity_x(rad/sec)</th>\n",
       "      <th>angular_velocity_z(rad/sec)</th>\n",
       "      <th>outlier_counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.503442</td>\n",
       "      <td>1.170089</td>\n",
       "      <td>0.972815</td>\n",
       "      <td>1.134731</td>\n",
       "      <td>0.762650</td>\n",
       "      <td>1.799946</td>\n",
       "      <td>3.626207</td>\n",
       "      <td>6.179145</td>\n",
       "      <td>1.825742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.311645</td>\n",
       "      <td>0.226445</td>\n",
       "      <td>0.211744</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>0.410482</td>\n",
       "      <td>1.881964</td>\n",
       "      <td>0.805034</td>\n",
       "      <td>1.253804</td>\n",
       "      <td>0.555718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acceleration_x(g)  acceleration_y(g)  acceleration_z(g)  roll(rad)  \\\n",
       "label                                                                       \n",
       "0.0             1.503442           1.170089           0.972815   1.134731   \n",
       "1.0             0.311645           0.226445           0.211744   0.484516   \n",
       "\n",
       "       pitch(rad)  yaw(rad)  angular_velocity_x(rad/sec)  \\\n",
       "label                                                      \n",
       "0.0      0.762650  1.799946                     3.626207   \n",
       "1.0      0.410482  1.881964                     0.805034   \n",
       "\n",
       "       angular_velocity_z(rad/sec)  outlier_counts  \n",
       "label                                               \n",
       "0.0                       6.179145        1.825742  \n",
       "1.0                       1.253804        0.555718  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.groupby('label').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The variance look very different. We can apply a either an F-test to see of the variances are equal. But before that lets see if the distributions are normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.294317Z",
     "start_time": "2020-05-31T19:28:27.255332Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acceleration_x(g)</td>\n",
       "      <td>(48331.53242501518, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acceleration_y(g)</td>\n",
       "      <td>(99262.97243275064, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acceleration_z(g)</td>\n",
       "      <td>(79202.278579982, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roll(rad)</td>\n",
       "      <td>(14021.489936568762, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pitch(rad)</td>\n",
       "      <td>(7041.943555582621, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yaw(rad)</td>\n",
       "      <td>(40489.37398100806, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angular_velocity_x(rad/sec)</td>\n",
       "      <td>(38884.515952611364, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angular_velocity_z(rad/sec)</td>\n",
       "      <td>(41179.290053697805, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>outlier_counts</td>\n",
       "      <td>(81223.15804426529, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0                          1\n",
       "0            acceleration_x(g)   (48331.53242501518, 0.0)\n",
       "1            acceleration_y(g)   (99262.97243275064, 0.0)\n",
       "2            acceleration_z(g)     (79202.278579982, 0.0)\n",
       "3                    roll(rad)  (14021.489936568762, 0.0)\n",
       "4                   pitch(rad)   (7041.943555582621, 0.0)\n",
       "5                     yaw(rad)   (40489.37398100806, 0.0)\n",
       "6  angular_velocity_x(rad/sec)  (38884.515952611364, 0.0)\n",
       "7  angular_velocity_z(rad/sec)  (41179.290053697805, 0.0)\n",
       "8               outlier_counts   (81223.15804426529, 0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "normality_tests = pd.DataFrame([col, stats.normaltest(phone_shake_data[col])] for col in phone_shake_data if col not in ['label', 'sensor_type'])\n",
    "normality_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using a p-value = 0.05, we have to reject the null hypotheses for all variables. Because our data violates two important assumptions of the t-test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since the above assumptions are violated, let's apply Mann Whitney U test. Mannu Whitney U test is a non parametric test and is useful when t-test assumptions are being violated. From this test we will get the p-values under the numm hypothesis that both groups are from identical distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:27.500784Z",
     "start_time": "2020-05-31T19:28:27.296448Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acceleration_x(g)</td>\n",
       "      <td>1.21402e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acceleration_y(g)</td>\n",
       "      <td>6.10027e-193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acceleration_z(g)</td>\n",
       "      <td>0.0672456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roll(rad)</td>\n",
       "      <td>2.13668e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pitch(rad)</td>\n",
       "      <td>3.59271e-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yaw(rad)</td>\n",
       "      <td>2.23309e-114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angular_velocity_x(rad/sec)</td>\n",
       "      <td>0.175571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angular_velocity_z(rad/sec)</td>\n",
       "      <td>1.0895e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>outlier_counts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0             1\n",
       "0            acceleration_x(g)   1.21402e-17\n",
       "1            acceleration_y(g)  6.10027e-193\n",
       "2            acceleration_z(g)     0.0672456\n",
       "3                    roll(rad)   2.13668e-10\n",
       "4                   pitch(rad)   3.59271e-55\n",
       "5                     yaw(rad)  2.23309e-114\n",
       "6  angular_velocity_x(rad/sec)      0.175571\n",
       "7  angular_velocity_z(rad/sec)    1.0895e-05\n",
       "8               outlier_counts             0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannWhitneyU_tests = []\n",
    "zero_index = phone_shake_data.loc[phone_shake_data['label']==0,:].index\n",
    "ones_index = phone_shake_data.loc[phone_shake_data['label']==1,:].index\n",
    "\n",
    "# peform the test and get p-values\n",
    "for col in phone_shake_data:\n",
    "    if col not in ['label', 'sensor_type']:\n",
    "        mannWhitneyU_tests.append( stats.mannwhitneyu(phone_shake_data.loc[zero_index, col], phone_shake_data.loc[ones_index, col])[1])\n",
    "\n",
    "# display results\n",
    "pd.DataFrame([[col for col in phone_shake_data if col not in ['label', 'sensor_type']], mannWhitneyU_tests]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking at the p values, the Mann Whitney U test suggests that the null hypothesis (both groups are from identical distributions) can be rejected for all except `roll(rad)`,`angular_velocity_x(rad/sec)`. These two may not be very important features. \n",
    "\n",
    "This suggests that despite the imbalance, we may have strong predictors in the data. Tree based models might do well in these cases. Let's take a look at the distributions of these variables across the two labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:30.427140Z",
     "start_time": "2020-05-31T19:28:27.503117Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1280 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "i = 1\n",
    "plt.figure(figsize=(20, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for num_col in numeric_cols:    \n",
    "    plt.subplot(9, 2, i)  # 1 line, 2 rows, index nr 1 (first position in the subplot)\n",
    "    plt.hist(phone_shake_data.loc[zero_index, num_col], 200, alpha=0.75, color=\"b\")\n",
    "    plt.xlabel('zeros')\n",
    "    plt.ylabel(num_col)\n",
    "    i+=1\n",
    "    plt.subplot(9, 2, i)  # 1 line, 2 rows, index nr 2 (second position in the subplot)\n",
    "    plt.hist(phone_shake_data.loc[ones_index, num_col], 200, alpha=0.75, color=\"g\")\n",
    "    plt.xlabel('ones')\n",
    "    plt.ylabel(num_col)\n",
    "    i+=1\n",
    "\n",
    "plt.subplots_adjust(left=1.25, bottom=0.1, right=1.9, top=0.9, wspace=0.3, hspace=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a useful plot for us. We know that the number of zeros in our dataset only three percent and ones are 97%. Inspite of this, the the distribution of ones is very very centred. The distribution of zeros on the other hand is more spread out. Let's look at the standard deviations once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:28:30.456008Z",
     "start_time": "2020-05-31T19:28:30.429124Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_x(g)</th>\n",
       "      <th>acceleration_y(g)</th>\n",
       "      <th>acceleration_z(g)</th>\n",
       "      <th>roll(rad)</th>\n",
       "      <th>pitch(rad)</th>\n",
       "      <th>yaw(rad)</th>\n",
       "      <th>angular_velocity_x(rad/sec)</th>\n",
       "      <th>angular_velocity_z(rad/sec)</th>\n",
       "      <th>outlier_counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.503442</td>\n",
       "      <td>1.170089</td>\n",
       "      <td>0.972815</td>\n",
       "      <td>1.134731</td>\n",
       "      <td>0.762650</td>\n",
       "      <td>1.799946</td>\n",
       "      <td>3.626207</td>\n",
       "      <td>6.179145</td>\n",
       "      <td>1.825742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.311645</td>\n",
       "      <td>0.226445</td>\n",
       "      <td>0.211744</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>0.410482</td>\n",
       "      <td>1.881964</td>\n",
       "      <td>0.805034</td>\n",
       "      <td>1.253804</td>\n",
       "      <td>0.555718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acceleration_x(g)  acceleration_y(g)  acceleration_z(g)  roll(rad)  \\\n",
       "label                                                                       \n",
       "0.0             1.503442           1.170089           0.972815   1.134731   \n",
       "1.0             0.311645           0.226445           0.211744   0.484516   \n",
       "\n",
       "       pitch(rad)  yaw(rad)  angular_velocity_x(rad/sec)  \\\n",
       "label                                                      \n",
       "0.0      0.762650  1.799946                     3.626207   \n",
       "1.0      0.410482  1.881964                     0.805034   \n",
       "\n",
       "       angular_velocity_z(rad/sec)  outlier_counts  \n",
       "label                                               \n",
       "0.0                       6.179145        1.825742  \n",
       "1.0                       1.253804        0.555718  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.groupby('label').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Given that 97 percent of the data is ones, I was expecting data for `label==1` to be more spread out. But understanding that since `label=1` implies end of shake motion, this distribution seems fine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Latent Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The next thing I want to look at is if there is a latent structure in the dataset. I'm going to use K-Means clustering and PCA for that. \n",
    "\n",
    "### K Means\n",
    "The idea of using K means is to see if there is any latent structure. After selecting the appropriate number of clusters, I will add two set of variables\n",
    "- cluster number to the dataset and see the distribution of labels across clusters. \n",
    "- distance from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:10.650892Z",
     "start_time": "2020-05-31T19:28:30.458040Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 002 WSSE is 682052.276029\n",
      "For k = 003 WSSE is 607928.333134\n",
      "For k = 004 WSSE is 557237.514108\n",
      "For k = 005 WSSE is 514085.021047\n",
      "For k = 006 WSSE is 479132.389410\n",
      "For k = 007 WSSE is 451596.773563\n",
      "For k = 008 WSSE is 432165.837520\n",
      "For k = 009 WSSE is 414676.748351\n",
      "For k = 010 WSSE is 397700.877929\n",
      "For k = 011 WSSE is 383695.122162\n",
      "For k = 012 WSSE is 371624.462840\n",
      "For k = 013 WSSE is 361038.971355\n",
      "For k = 014 WSSE is 352178.435402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# train the center scaler\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "ss = StandardScaler(with_std=True, with_mean=True)\n",
    "ss.fit(phone_shake_data.loc[:, numeric_cols])\n",
    "\n",
    "# center scale the data\n",
    "phone_shake_data_scaled = pd.DataFrame(ss.transform(phone_shake_data.loc[:, numeric_cols]))\n",
    "\n",
    "# perform clustering for different cluster numbers\n",
    "wsse_collect = []\n",
    "k_min = 2\n",
    "k_max = 15\n",
    "for i in range(k_min, k_max):\n",
    "    km = KMeans(random_state=42, max_iter=200, n_clusters=i)\n",
    "    _ = km.fit(phone_shake_data_scaled)\n",
    "    wsse = km.inertia_\n",
    "    print('For k = {i:03d} WSSE is {wsse:10f}'.format(i=i, wsse=round(wsse,200)))\n",
    "    wsse_collect.append(wsse)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T20:24:49.520481Z",
     "start_time": "2020-05-31T20:19:04.008Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot the within cluster sum of square \n",
    "plt.style.use('seaborn-deep')\n",
    "plt.plot(range(k_min, k_max), wsse_collect, 'b',alpha=.55)\n",
    "plt.plot(7, wsse_collect[8], 'r.', alpha=.95, ms=10)\n",
    "plt.ylabel(\"Within cluster SSE\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I am going to select 7 as the optimal number of clusters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:13.032178Z",
     "start_time": "2020-05-31T19:29:10.807934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train the K Means model with 7 clusters\n",
    "n_clusters = 7\n",
    "km = KMeans(random_state=42, max_iter=200, n_clusters=n_clusters)\n",
    "_ = km.fit(phone_shake_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:13.074734Z",
     "start_time": "2020-05-31T19:29:13.034392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add the clustering features\n",
    "phone_shake_data.loc[:,\"cluster_number\"] = km.predict(phone_shake_data_scaled)\n",
    "distance_from_cluster = km.transform(phone_shake_data_scaled)\n",
    "distance_from_cluster = pd.DataFrame(distance_from_cluster, columns=[\"distance_from_cluster_\"+str(i) for i in range(0, n_clusters)])\n",
    "\n",
    "# merge the data\n",
    "phone_shake_data = phone_shake_data.merge(distance_from_cluster, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cluster Analysis\n",
    "\n",
    "Now that we have done our clustering. Let's see what kind of results we got from that exercise. I am going to look at\n",
    "- the cluster wise mean of our target variable-  `label`\n",
    "- the number of rows in each cluster\n",
    "- the mean of the variables across the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:13.098807Z",
     "start_time": "2020-05-31T19:29:13.076888Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_number\n",
       "0    0.983183\n",
       "1    0.994196\n",
       "2    0.797757\n",
       "3    0.954916\n",
       "4    0.891322\n",
       "5    0.496324\n",
       "6    0.618009\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the cluster wise event rate\n",
    "phone_shake_data.groupby('cluster_number')['label'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have two groups of clusters forming here. On one hand we have Clusters 2,4,5 and 6 with the lowest event rates while on the other hand, clusters 0, 1 and 5 have the highest event rates. Lets check how much percentage of total data lies in these two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:13.120844Z",
     "start_time": "2020-05-31T19:29:13.112069Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_number\n",
       "0    25.650493\n",
       "1    59.065498\n",
       "2     2.872294\n",
       "3     7.475786\n",
       "4     2.783721\n",
       "5     0.938643\n",
       "6     1.213564\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*phone_shake_data.groupby('cluster_number')['label'].count()/phone_shake_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Clusters 0 and 1 account for three-fourths of our data. This looks useful. We'll see how it does in the models. We also have taken cluster distances in our dataset. Lets see how they relate with the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:13.149488Z",
     "start_time": "2020-05-31T19:29:13.130995Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_cluster_0</th>\n",
       "      <th>distance_from_cluster_1</th>\n",
       "      <th>distance_from_cluster_2</th>\n",
       "      <th>distance_from_cluster_3</th>\n",
       "      <th>distance_from_cluster_4</th>\n",
       "      <th>distance_from_cluster_5</th>\n",
       "      <th>distance_from_cluster_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>8.263061</td>\n",
       "      <td>8.321520</td>\n",
       "      <td>8.779548</td>\n",
       "      <td>8.711568</td>\n",
       "      <td>8.848802</td>\n",
       "      <td>10.798159</td>\n",
       "      <td>10.014690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.349495</td>\n",
       "      <td>1.776491</td>\n",
       "      <td>5.444479</td>\n",
       "      <td>3.474924</td>\n",
       "      <td>4.273160</td>\n",
       "      <td>9.125890</td>\n",
       "      <td>7.869939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       distance_from_cluster_0  distance_from_cluster_1  \\\n",
       "label                                                     \n",
       "0.0                   8.263061                 8.321520   \n",
       "1.0                   2.349495                 1.776491   \n",
       "\n",
       "       distance_from_cluster_2  distance_from_cluster_3  \\\n",
       "label                                                     \n",
       "0.0                   8.779548                 8.711568   \n",
       "1.0                   5.444479                 3.474924   \n",
       "\n",
       "       distance_from_cluster_4  distance_from_cluster_5  \\\n",
       "label                                                     \n",
       "0.0                   8.848802                10.798159   \n",
       "1.0                   4.273160                 9.125890   \n",
       "\n",
       "       distance_from_cluster_6  \n",
       "label                           \n",
       "0.0                  10.014690  \n",
       "1.0                   7.869939  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.groupby('label')[[\"distance_from_cluster_\"+str(i) for i in range(0, n_clusters)]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The means of a few distances look quite different. I am not sure if there is a statistical test that can be used in this scenario to see if these cluster means are significantly different. \n",
    "\n",
    "### PCA\n",
    "The second part in our attempt to find latent structure revolves around PCA. The idea is simple. Train a PCA model and see if we can get if these variables are good indicators. \n",
    "\n",
    "The problem with this approach is that PCA is based on Pearson correlation coefficient and assumes that there is a linear relationship with all variables. But since lot of the given features are variables in independent direction- `acceleration_x(g), acceleration_y(g)`, we cannot rely on this method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Checking for multicollinearity in the newly added features\n",
    "\n",
    "We've added a handful of features. The distance features that we picked up from KMeans often have high multicollinearity. This is expected behavior. So in each step I will- \n",
    "- calculate the VIF for each variable, \n",
    "- delete the variable with highest VIF score (given that their VIF score is > 5)\n",
    "- repeat until all remaining variables have VIF under 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:14.243464Z",
     "start_time": "2020-05-31T19:29:13.151861Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          466.365006\n",
       "acceleration_x(g)                7.481648\n",
       "acceleration_y(g)                2.982452\n",
       "acceleration_z(g)                4.321960\n",
       "roll(rad)                       10.522018\n",
       "pitch(rad)                       6.800106\n",
       "yaw(rad)                         7.856432\n",
       "angular_velocity_x(rad/sec)      6.338166\n",
       "angular_velocity_z(rad/sec)      4.039489\n",
       "outlier_counts                  10.532517\n",
       "cluster_number                   4.881399\n",
       "distance_from_cluster_0         49.817396\n",
       "distance_from_cluster_1         31.816849\n",
       "distance_from_cluster_2         40.252507\n",
       "distance_from_cluster_3         46.977570\n",
       "distance_from_cluster_4         64.163915\n",
       "distance_from_cluster_5         12.409318\n",
       "distance_from_cluster_6         21.722797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for multicollinearity using VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "# add a constant because statsmodels' VIF doesn't add a constant\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "X = add_constant(phone_shake_data[numeric_cols])\n",
    "pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:15.112735Z",
     "start_time": "2020-05-31T19:29:14.245828Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          408.913551\n",
       "acceleration_x(g)                7.479693\n",
       "acceleration_y(g)                1.898464\n",
       "acceleration_z(g)                4.100130\n",
       "roll(rad)                        2.077954\n",
       "pitch(rad)                       6.249977\n",
       "yaw(rad)                         7.539152\n",
       "angular_velocity_x(rad/sec)      6.137281\n",
       "angular_velocity_z(rad/sec)      3.939166\n",
       "outlier_counts                   9.424188\n",
       "cluster_number                   4.827463\n",
       "distance_from_cluster_0         41.902290\n",
       "distance_from_cluster_1         30.328149\n",
       "distance_from_cluster_2         39.676601\n",
       "distance_from_cluster_3         46.737994\n",
       "distance_from_cluster_5         11.329096\n",
       "distance_from_cluster_6         18.715387\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.drop('distance_from_cluster_4', axis=1, inplace=True)\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "X = add_constant(phone_shake_data[numeric_cols])\n",
    "pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:15.900453Z",
     "start_time": "2020-05-31T19:29:15.115170Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          408.912701\n",
       "acceleration_x(g)                7.462798\n",
       "acceleration_y(g)                1.815058\n",
       "acceleration_z(g)                4.096640\n",
       "roll(rad)                        1.339759\n",
       "pitch(rad)                       1.851603\n",
       "yaw(rad)                         7.147379\n",
       "angular_velocity_x(rad/sec)      6.080281\n",
       "angular_velocity_z(rad/sec)      3.933524\n",
       "outlier_counts                   6.777659\n",
       "cluster_number                   4.185274\n",
       "distance_from_cluster_0         35.763112\n",
       "distance_from_cluster_1         26.478600\n",
       "distance_from_cluster_2         39.402150\n",
       "distance_from_cluster_5         11.296718\n",
       "distance_from_cluster_6         18.319135\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.drop('distance_from_cluster_3', axis=1, inplace=True)\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "X = add_constant(phone_shake_data[numeric_cols])\n",
    "pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:16.570606Z",
     "start_time": "2020-05-31T19:29:15.902711Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          346.679609\n",
       "acceleration_x(g)                1.383273\n",
       "acceleration_y(g)                1.735822\n",
       "acceleration_z(g)                1.170836\n",
       "roll(rad)                        1.338475\n",
       "pitch(rad)                       1.847640\n",
       "yaw(rad)                         7.141277\n",
       "angular_velocity_x(rad/sec)      5.911242\n",
       "angular_velocity_z(rad/sec)      3.926054\n",
       "outlier_counts                   5.175560\n",
       "cluster_number                   4.147186\n",
       "distance_from_cluster_0         35.286702\n",
       "distance_from_cluster_1         25.489568\n",
       "distance_from_cluster_5          8.900189\n",
       "distance_from_cluster_6         12.786482\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.drop('distance_from_cluster_2', axis=1, inplace=True)\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "X = add_constant(phone_shake_data[numeric_cols])\n",
    "pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:17.149679Z",
     "start_time": "2020-05-31T19:29:16.572863Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          282.933972\n",
       "acceleration_x(g)                1.365834\n",
       "acceleration_y(g)                1.633716\n",
       "acceleration_z(g)                1.170793\n",
       "roll(rad)                        1.227058\n",
       "pitch(rad)                       1.847314\n",
       "yaw(rad)                         2.791875\n",
       "angular_velocity_x(rad/sec)      5.898146\n",
       "angular_velocity_z(rad/sec)      3.923587\n",
       "outlier_counts                   4.382144\n",
       "cluster_number                   3.356181\n",
       "distance_from_cluster_1         11.457052\n",
       "distance_from_cluster_5          8.735630\n",
       "distance_from_cluster_6         12.123101\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.drop('distance_from_cluster_0', axis=1, inplace=True)\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "X = add_constant(phone_shake_data[numeric_cols])\n",
    "pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:17.648878Z",
     "start_time": "2020-05-31T19:29:17.152077Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          264.485330\n",
       "acceleration_x(g)                1.183225\n",
       "acceleration_y(g)                1.620645\n",
       "acceleration_z(g)                1.099380\n",
       "roll(rad)                        1.222139\n",
       "pitch(rad)                       1.763706\n",
       "yaw(rad)                         2.651004\n",
       "angular_velocity_x(rad/sec)      1.407068\n",
       "angular_velocity_z(rad/sec)      1.300819\n",
       "outlier_counts                   4.381426\n",
       "cluster_number                   3.318327\n",
       "distance_from_cluster_1         10.169866\n",
       "distance_from_cluster_5          3.445686\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.drop(['distance_from_cluster_6'], axis=1, inplace=True)\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "X = add_constant(phone_shake_data[numeric_cols])\n",
    "pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:18.082053Z",
     "start_time": "2020-05-31T19:29:17.651147Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          182.219911\n",
       "acceleration_x(g)                1.182867\n",
       "acceleration_y(g)                1.480223\n",
       "acceleration_z(g)                1.084435\n",
       "roll(rad)                        1.213595\n",
       "pitch(rad)                       1.720393\n",
       "yaw(rad)                         1.193296\n",
       "angular_velocity_x(rad/sec)      1.215314\n",
       "angular_velocity_z(rad/sec)      1.155933\n",
       "outlier_counts                   2.686758\n",
       "cluster_number                   2.680874\n",
       "distance_from_cluster_5          2.097570\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_shake_data.drop(['distance_from_cluster_1'], axis=1, inplace=True)\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "X = add_constant(phone_shake_data[numeric_cols])\n",
    "pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adding acceleration and angular velocity vectors.\n",
    "\n",
    "Since we have the x, y, z components of acceleration and angular velocity, I am going to add them up and see if the resulting features have any value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:18.096590Z",
     "start_time": "2020-05-31T19:29:18.084168Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phone_shake_data.loc[:, \"acceleration\"] = phone_shake_data.loc[:, \"acceleration_x(g)\"]**2 + phone_shake_data.loc[:, \"acceleration_y(g)\"]**2 + phone_shake_data.loc[:, \"acceleration_z(g)\"]**2 \n",
    "\n",
    "phone_shake_data.loc[:, \"acceleration\"] = phone_shake_data.loc[:, \"acceleration\"]**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:18.111406Z",
     "start_time": "2020-05-31T19:29:18.098757Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phone_shake_data.loc[:, \"angular_velocity\"] = phone_shake_data.loc[:, \"angular_velocity_x(rad/sec)\"]**2 + phone_shake_data.loc[:, \"angular_velocity_x(rad/sec)\"]**2 + phone_shake_data.loc[:, \"angular_velocity_z(rad/sec)\"]**2 \n",
    "\n",
    "phone_shake_data.loc[:, \"angular_velocity\"] = phone_shake_data.loc[:, \"angular_velocity\"]**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I am going to build a logisitc, xgboost, random forest and decision tree model.  Since we have an imbalanced dataset on our hands, I am going to \n",
    "- use _F1_ as our evaluation metric\n",
    "- use `class_weight='balanced'` wherever possible. This is so that algorithm adjusts weights of the classes inversely proportional to their frequencies in the input data\n",
    "\n",
    "Also, I am using 5 fold cross validation to report the evaluation metrics. There are many models to pick from but I'll be sticking to these four models- \n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Logisitc Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Logisitc Regression with added features\n",
    "I'll build two models here. One with the original variables and one with the cluster features. Lets see if our insights so far our correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:20.603474Z",
     "start_time": "2020-05-31T19:29:18.113250Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with added features F1: 0.92 (+/- 0.25)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# select numeric columns\n",
    "numeric_cols = [i for i in phone_shake_data.columns if i not in ['sensor_type', 'label']]\n",
    "\n",
    "# train logistic model\n",
    "lr = LogisticRegression(class_weight=\"balanced\", random_state=42, verbose=0, solver='lbfgs', max_iter=1000)\n",
    "lr_scores = cross_val_score(lr, phone_shake_data[numeric_cols], phone_shake_data['label'], cv=5, scoring='f1')\n",
    "\n",
    "print(\"Logistic Regression with added features F1: %0.2f (+/- %0.2f)\" % (lr_scores.mean(), lr_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Logisitic Regression with the given variables only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:21.197933Z",
     "start_time": "2020-05-31T19:29:20.606059Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Original variables F1: 0.78 (+/- 0.37)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# initialize model\n",
    "lr = LogisticRegression(class_weight=\"balanced\", random_state=42, verbose=0, solver='lbfgs', max_iter=1000)\n",
    "original_cols = ['acceleration_x(g)', 'acceleration_y(g)', 'acceleration_z(g)', 'roll(rad)', 'pitch(rad)', 'yaw(rad)', 'angular_velocity_x(rad/sec)', 'angular_velocity_z(rad/sec)']\n",
    "\n",
    "# train with cross validation\n",
    "lr_scores = cross_val_score(lr, phone_shake_data[original_cols], phone_shake_data['label'], cv=5, scoring='f1')\n",
    "print(\"Logistic Regression with Original variables F1: %0.2f (+/- %0.2f)\" % (lr_scores.mean(), lr_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Adding clustering features has not only improved the average score, its also making the model more stable. I am not going to include this comparison for the rest of the models. I just wanted to see/show if the variables I created are adding any value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Summary of Logistic Regression model\n",
    "\n",
    "Since _sklearn_ doesn't provide p-values and other statistical measurements for regression models, I am using the _statsmodels_ api to get the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:21.876194Z",
     "start_time": "2020-05-31T19:29:21.200519Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.080029\n",
      "         Iterations 9\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit = sm.Logit(phone_shake_data['label'], sm.add_constant(phone_shake_data[numeric_cols]))\n",
    "logit_fit = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:29:22.063343Z",
     "start_time": "2020-05-31T19:29:21.878656Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>label</td>      <th>  No. Observations:  </th>  <td> 86934</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 86920</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 01 Jun 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.3953</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>00:59:22</td>     <th>  Log-Likelihood:    </th> <td> -6957.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -11504.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                       <td>    2.0366</td> <td>    0.239</td> <td>    8.522</td> <td> 0.000</td> <td>    1.568</td> <td>    2.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration_x(g)</th>           <td>   -0.1168</td> <td>    0.031</td> <td>   -3.794</td> <td> 0.000</td> <td>   -0.177</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration_y(g)</th>           <td>    0.6703</td> <td>    0.052</td> <td>   12.769</td> <td> 0.000</td> <td>    0.567</td> <td>    0.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration_z(g)</th>           <td>    0.1860</td> <td>    0.047</td> <td>    3.954</td> <td> 0.000</td> <td>    0.094</td> <td>    0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roll(rad)</th>                   <td>    0.0280</td> <td>    0.028</td> <td>    0.984</td> <td> 0.325</td> <td>   -0.028</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pitch(rad)</th>                  <td>   -0.4135</td> <td>    0.044</td> <td>   -9.349</td> <td> 0.000</td> <td>   -0.500</td> <td>   -0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yaw(rad)</th>                    <td>    0.0959</td> <td>    0.014</td> <td>    6.859</td> <td> 0.000</td> <td>    0.068</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>angular_velocity_x(rad/sec)</th> <td>   -0.1101</td> <td>    0.014</td> <td>   -8.077</td> <td> 0.000</td> <td>   -0.137</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>angular_velocity_z(rad/sec)</th> <td>    0.0740</td> <td>    0.008</td> <td>    9.022</td> <td> 0.000</td> <td>    0.058</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>outlier_counts</th>              <td>    0.3230</td> <td>    0.033</td> <td>    9.646</td> <td> 0.000</td> <td>    0.257</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_number</th>              <td>   -0.1484</td> <td>    0.022</td> <td>   -6.828</td> <td> 0.000</td> <td>   -0.191</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_from_cluster_5</th>     <td>    0.3599</td> <td>    0.027</td> <td>   13.158</td> <td> 0.000</td> <td>    0.306</td> <td>    0.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th>                <td>   -2.1827</td> <td>    0.051</td> <td>  -42.639</td> <td> 0.000</td> <td>   -2.283</td> <td>   -2.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>angular_velocity</th>            <td>   -0.2691</td> <td>    0.012</td> <td>  -22.318</td> <td> 0.000</td> <td>   -0.293</td> <td>   -0.246</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  label   No. Observations:                86934\n",
       "Model:                          Logit   Df Residuals:                    86920\n",
       "Method:                           MLE   Df Model:                           13\n",
       "Date:                Mon, 01 Jun 2020   Pseudo R-squ.:                  0.3953\n",
       "Time:                        00:59:22   Log-Likelihood:                -6957.2\n",
       "converged:                       True   LL-Null:                       -11504.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "===============================================================================================\n",
       "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "const                           2.0366      0.239      8.522      0.000       1.568       2.505\n",
       "acceleration_x(g)              -0.1168      0.031     -3.794      0.000      -0.177      -0.056\n",
       "acceleration_y(g)               0.6703      0.052     12.769      0.000       0.567       0.773\n",
       "acceleration_z(g)               0.1860      0.047      3.954      0.000       0.094       0.278\n",
       "roll(rad)                       0.0280      0.028      0.984      0.325      -0.028       0.084\n",
       "pitch(rad)                     -0.4135      0.044     -9.349      0.000      -0.500      -0.327\n",
       "yaw(rad)                        0.0959      0.014      6.859      0.000       0.068       0.123\n",
       "angular_velocity_x(rad/sec)    -0.1101      0.014     -8.077      0.000      -0.137      -0.083\n",
       "angular_velocity_z(rad/sec)     0.0740      0.008      9.022      0.000       0.058       0.090\n",
       "outlier_counts                  0.3230      0.033      9.646      0.000       0.257       0.389\n",
       "cluster_number                 -0.1484      0.022     -6.828      0.000      -0.191      -0.106\n",
       "distance_from_cluster_5         0.3599      0.027     13.158      0.000       0.306       0.413\n",
       "acceleration                   -2.1827      0.051    -42.639      0.000      -2.283      -2.082\n",
       "angular_velocity               -0.2691      0.012    -22.318      0.000      -0.293      -0.246\n",
       "===============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:30:01.145813Z",
     "start_time": "2020-05-31T19:29:22.066001Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1: 0.89 (+/- 0.30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initialize model\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=12, min_samples_split=3, min_samples_leaf=1, max_features='auto', min_impurity_decrease=10**-3, random_state=42, class_weight=\"balanced_subsample\")\n",
    "\n",
    "# train with cross validation\n",
    "rf_scores = cross_val_score(rf, phone_shake_data[numeric_cols], phone_shake_data['label'], cv=5, scoring='f1')\n",
    "print(\"Random Forest F1: %0.2f (+/- %0.2f)\" % (rf_scores.mean(), rf_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:30:10.606726Z",
     "start_time": "2020-05-31T19:30:01.147950Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rf_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angular_velocity</td>\n",
       "      <td>0.243208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>0.233795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outlier_counts</td>\n",
       "      <td>0.151643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distance_from_cluster_5</td>\n",
       "      <td>0.0849706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acceleration_y(g)</td>\n",
       "      <td>0.0772178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cluster_number</td>\n",
       "      <td>0.0705915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acceleration_x(g)</td>\n",
       "      <td>0.0456815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angular_velocity_z(rad/sec)</td>\n",
       "      <td>0.0437702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>angular_velocity_x(rad/sec)</td>\n",
       "      <td>0.02027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yaw(rad)</td>\n",
       "      <td>0.0101188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pitch(rad)</td>\n",
       "      <td>0.00787955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>roll(rad)</td>\n",
       "      <td>0.00605383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acceleration_z(g)</td>\n",
       "      <td>0.00479959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature rf_importance\n",
       "0              angular_velocity      0.243208\n",
       "1                  acceleration      0.233795\n",
       "2                outlier_counts      0.151643\n",
       "3       distance_from_cluster_5     0.0849706\n",
       "4             acceleration_y(g)     0.0772178\n",
       "5                cluster_number     0.0705915\n",
       "6             acceleration_x(g)     0.0456815\n",
       "7   angular_velocity_z(rad/sec)     0.0437702\n",
       "8   angular_velocity_x(rad/sec)       0.02027\n",
       "9                      yaw(rad)     0.0101188\n",
       "10                   pitch(rad)    0.00787955\n",
       "11                    roll(rad)    0.00605383\n",
       "12            acceleration_z(g)    0.00479959"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(phone_shake_data[numeric_cols], phone_shake_data['label'])\n",
    "rf_importances = pd.DataFrame([numeric_cols, rf.feature_importances_]).transpose()\n",
    "rf_importances.columns = ['feature', 'rf_importance']\n",
    "rf_importances = rf_importances.sort_values(by='rf_importance', ascending=False).reset_index().drop(\"index\", axis=1)\n",
    "rf_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The variables I created seem to be doing well in the random forest model. Also, in section , we estimated that `roll(rad)` might not be quite useful and so it seems to be here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:31:56.053336Z",
     "start_time": "2020-05-31T19:30:10.608885Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1: 0.94 (+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# initialize model\n",
    "xgb = xgboost.XGBClassifier(objective='binary:logistic', random_state=42, max_depth=12)\n",
    "\n",
    "# train with cross validation\n",
    "xgb_scores = cross_val_score(xgb, phone_shake_data[numeric_cols], phone_shake_data['label'], cv=5, scoring='f1')\n",
    "print(\"XGBoost F1: %0.2f (+/- %0.2f)\" % (xgb_scores.mean(), xgb_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:32:23.374970Z",
     "start_time": "2020-05-31T19:31:56.055460Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(objective='binary:logistic', random_state=42, max_depth=12)\n",
    "_ = xgb.fit(phone_shake_data[numeric_cols], phone_shake_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:32:23.556430Z",
     "start_time": "2020-05-31T19:32:23.377005Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>xgb_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>0.356262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angular_velocity</td>\n",
       "      <td>0.13172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cluster_number</td>\n",
       "      <td>0.0601349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yaw(rad)</td>\n",
       "      <td>0.0537647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pitch(rad)</td>\n",
       "      <td>0.0520796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roll(rad)</td>\n",
       "      <td>0.0517437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acceleration_x(g)</td>\n",
       "      <td>0.0457271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acceleration_z(g)</td>\n",
       "      <td>0.0454941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acceleration_y(g)</td>\n",
       "      <td>0.0447633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angular_velocity_z(rad/sec)</td>\n",
       "      <td>0.0413676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>distance_from_cluster_5</td>\n",
       "      <td>0.0398837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>outlier_counts</td>\n",
       "      <td>0.0398763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>angular_velocity_x(rad/sec)</td>\n",
       "      <td>0.0371829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature xgb_importance\n",
       "0                  acceleration       0.356262\n",
       "1              angular_velocity        0.13172\n",
       "2                cluster_number      0.0601349\n",
       "3                      yaw(rad)      0.0537647\n",
       "4                    pitch(rad)      0.0520796\n",
       "5                     roll(rad)      0.0517437\n",
       "6             acceleration_x(g)      0.0457271\n",
       "7             acceleration_z(g)      0.0454941\n",
       "8             acceleration_y(g)      0.0447633\n",
       "9   angular_velocity_z(rad/sec)      0.0413676\n",
       "10      distance_from_cluster_5      0.0398837\n",
       "11               outlier_counts      0.0398763\n",
       "12  angular_velocity_x(rad/sec)      0.0371829"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_importances = pd.DataFrame([numeric_cols, xgb.feature_importances_]).transpose()\n",
    "xgb_importances.columns = ['feature', 'xgb_importance']\n",
    "xgb_importances = xgb_importances.sort_values(by='xgb_importance', ascending=False).reset_index().drop(\"index\", axis=1)\n",
    "xgb_importances"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our variables seem to be doing good here as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:36:22.681700Z",
     "start_time": "2020-05-31T19:32:23.558563Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost F1: 0.94 (+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# initialize model\n",
    "cb = CatBoostClassifier(iterations=200, eval_metric=\"F1\", random_seed=42, max_depth=12, logging_level='Silent')\n",
    "\n",
    "# train with cross validation\n",
    "cb_scores = cross_val_score(cb, phone_shake_data[numeric_cols], phone_shake_data['label'], cv=5, scoring='f1')\n",
    "print(\"CatBoost F1: %0.2f (+/- %0.2f)\" % (cb_scores.mean(), cb_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:36:35.855141Z",
     "start_time": "2020-05-31T19:36:22.683868Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1294fd550>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostClassifier(iterations=100, eval_metric=\"F1\", random_seed=42, max_depth=12)\n",
    "cb.fit(phone_shake_data[numeric_cols], phone_shake_data['label'], logging_level='Silent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:36:35.955117Z",
     "start_time": "2020-05-31T19:36:35.858101Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>cb_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yaw(rad)</td>\n",
       "      <td>24.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roll(rad)</td>\n",
       "      <td>13.7007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pitch(rad)</td>\n",
       "      <td>11.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angular_velocity</td>\n",
       "      <td>7.90542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angular_velocity_z(rad/sec)</td>\n",
       "      <td>6.7634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acceleration_x(g)</td>\n",
       "      <td>6.49436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acceleration_z(g)</td>\n",
       "      <td>6.3079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angular_velocity_x(rad/sec)</td>\n",
       "      <td>6.16798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>distance_from_cluster_5</td>\n",
       "      <td>5.2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acceleration_y(g)</td>\n",
       "      <td>4.75807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>4.05805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cluster_number</td>\n",
       "      <td>1.9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>outlier_counts</td>\n",
       "      <td>0.878894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature cb_importance\n",
       "0                      yaw(rad)        24.108\n",
       "1                     roll(rad)       13.7007\n",
       "2                    pitch(rad)        11.592\n",
       "3              angular_velocity       7.90542\n",
       "4   angular_velocity_z(rad/sec)        6.7634\n",
       "5             acceleration_x(g)       6.49436\n",
       "6             acceleration_z(g)        6.3079\n",
       "7   angular_velocity_x(rad/sec)       6.16798\n",
       "8       distance_from_cluster_5        5.2677\n",
       "9             acceleration_y(g)       4.75807\n",
       "10                 acceleration       4.05805\n",
       "11               cluster_number        1.9975\n",
       "12               outlier_counts      0.878894"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "cb_importances = pd.DataFrame([numeric_cols, cb.get_feature_importance()]).transpose()\n",
    "cb_importances.columns = ['feature', 'cb_importance']\n",
    "cb_importances = cb_importances.sort_values(by='cb_importance', ascending=False).reset_index().drop(\"index\", axis=1)\n",
    "cb_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All the features I created have moved to the bottom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TPOT Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "TPOT classifier is a genetic algorithm based classifier and is different from our ususal models. The aglorithm does well but runs for a long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:36:35.960186Z",
     "start_time": "2020-05-31T19:36:35.957489Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#from tpot import TPOTClassifier\n",
    "#tpot = TPOTClassifier(generations=1, population_size=50, verbosity=2, random_state=42)\n",
    "#tpot.fit(phone_shake_data[numeric_cols], phone_shake_data['label'])\n",
    "\n",
    "## train with cross validation\n",
    "#tpot_scores = cross_val_score(tpot, phone_shake_data[numeric_cols], phone_shake_data['label'], cv=3, scoring='f1')\n",
    "#print(\"CatBoost F1: %0.2f (+/- %0.2f)\" % (tpot_scores.mean(), tpot_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Balancing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have seen the models do reasonably well on our imbalanced dataset. I am going to try and add some balance to it and see how the models respond to it. \n",
    "\n",
    "I usually like that minority class to be atleast around 10-15 percent. So, in the resampled dataset I would want the zeros to be nearly 15 percent of the resampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:36:38.384303Z",
     "start_time": "2020-05-31T19:36:35.962650Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN as oversampler_\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# centre and scale the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(phone_shake_data[numeric_cols])\n",
    "\n",
    "# initialize and train the sampler\n",
    "oversampler = oversampler_(random_state=42, sampling_strategy=0.15)\n",
    "X_res, y_res = oversampler.fit_resample(ss.transform(phone_shake_data[numeric_cols]), phone_shake_data['label'])\n",
    "X_res = ss.inverse_transform(X_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets check the number of ones in the resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:36:38.403340Z",
     "start_time": "2020-05-31T19:36:38.386613Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8700125780976142"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Thats not 15 percent exactly but it's good enough to work with. In the next section, I'll retrain all the models from we trained above and see if we get better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  Modeling after balancing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:36:41.852450Z",
     "start_time": "2020-05-31T19:36:38.406766Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 with balanced data : 0.90 (+/- 0.27)\n"
     ]
    }
   ],
   "source": [
    "#################### LOGISTIC REGRESSION ####################\n",
    "# initialize model\n",
    "lr = LogisticRegression(class_weight=\"balanced\", random_state=42, verbose=0, solver='lbfgs', max_iter=1000)\n",
    "original_cols = ['acceleration_x(g)', 'acceleration_y(g)', 'acceleration_z(g)', 'roll(rad)', 'pitch(rad)', 'yaw(rad)', 'angular_velocity_x(rad/sec)', 'angular_velocity_z(rad/sec)']\n",
    "\n",
    "# train with cross validation\n",
    "lr_scores = cross_val_score(lr, X_res, y_res, cv=5, scoring='f1')\n",
    "print(\"Logistic Regression F1 with balanced data : %0.2f (+/- %0.2f)\" % (lr_scores.mean(), lr_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:37:28.797361Z",
     "start_time": "2020-05-31T19:36:41.855066Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1 with balanced data: 0.85 (+/- 0.34)\n"
     ]
    }
   ],
   "source": [
    "#################### RANDOM FOREST ########################\n",
    "# initialize model\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=12, min_samples_split=3, min_samples_leaf=1, max_features='auto', min_impurity_decrease=10**-3, random_state=42, class_weight=\"balanced_subsample\")\n",
    "\n",
    "# train with cross validation\n",
    "rf_scores = cross_val_score(rf, X_res, y_res, cv=5, scoring='f1')\n",
    "print(\"Random Forest F1 with balanced data: %0.2f (+/- %0.2f)\" % (rf_scores.mean(), rf_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:39:41.334611Z",
     "start_time": "2020-05-31T19:37:28.799520Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1 with balanced data : 0.90 (+/- 0.23)\n"
     ]
    }
   ],
   "source": [
    "#################### XGBOOST #############################\n",
    "# initialize model\n",
    "xgb = xgboost.XGBClassifier(objective='binary:logistic', random_state=42, max_depth=12)\n",
    "\n",
    "# train with cross validation\n",
    "xgb_scores = cross_val_score(xgb, X_res, y_res, cv=5, scoring='f1')\n",
    "print(\"XGBoost F1 with balanced data : %0.2f (+/- %0.2f)\" % (xgb_scores.mean(), xgb_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:44:52.024953Z",
     "start_time": "2020-05-31T19:39:41.336642Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost F1 with balanced data : 0.91 (+/- 0.24)\n"
     ]
    }
   ],
   "source": [
    "#################### CatBOOST ############################\n",
    "# initialize model\n",
    "cb = CatBoostClassifier(iterations=200, eval_metric=\"F1\", random_seed=42, max_depth=12, logging_level='Silent')\n",
    "\n",
    "# train with cross validation\n",
    "cb_scores = cross_val_score(cb, X_res, y_res, cv=5, scoring='f1')\n",
    "print(\"CatBoost F1 with balanced data : %0.2f (+/- %0.2f)\" % (cb_scores.mean(), cb_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Seeing the results from above experiments and working with different values of `sampling_strategy` and `k_neighbors` doesn't yield any increase in model performance. In fact, it has slightly reduced our model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have worked with four models above which have performed decently. Now it's time to up the model performance by tuning the model by searching across a hyper parameter space. \n",
    "\n",
    "I am using `skopt` package and the Gaussian Optimization routine for this optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T21:05:34.342785Z",
     "start_time": "2020-05-31T21:05:34.294564Z"
    },
    "code_folding": [
     4,
     42,
     50,
     58
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# logistic regression hyperparameter space\n",
    "lr_space = {\n",
    "    \"C\": Real(1, 100, prior='log-uniform'),\n",
    "    \"max_iter\": Real(300, 1000, prior='log-uniform')\n",
    "}\n",
    "\n",
    "\n",
    "# random forest hyperparameter space\n",
    "rf_space = {\n",
    "    \"n_estimators\": Integer(100, 200),\n",
    "    \"max_depth\": Integer(6, 32),\n",
    "    \"min_samples_split\": Integer(1, 100),\n",
    "    \"min_samples_leaf\": Integer(1, 200),\n",
    "    \"max_features\": Real(0.3, 0.7, prior='log-uniform'),\n",
    "    \"max_samples\": Real(0.3, 0.7, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "# xgboost hyperparameter space\n",
    "xgb_space = {\n",
    "    \"n_estimators\": Integer(100, 200),\n",
    "    \"max_depth\": Integer(6, 32),\n",
    "    \"gamma\": Real(0.01, 1, prior='log-uniform'),\n",
    "    \"learning_rate\": Real(0.0001, 1, prior='log-uniform'),\n",
    "    \"max_delta_step\": Real(0.1, 10, prior='log-uniform'),\n",
    "    \"reg_alpha\": Real(0.1, 100, prior='log-uniform'),\n",
    "    \"reg_lambda\": Real(0.1, 100, prior='log-uniform'),\n",
    "    \"subsample\": Real(0.3, 0.7, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "\n",
    "# catboost hyperparameter space\n",
    "cb_space = {\n",
    "    \"iterations\": Integer(100, 200),\n",
    "    \"max_depth\": Integer(6, 16),\n",
    "    \"learning_rate\": Real(0.0001, 1, prior='log-uniform'),\n",
    "    \"l2_leaf_reg\": Real(1, 10, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "n_iter = 2\n",
    "lr_opt = BayesSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    lr_space,\n",
    "    n_iter=n_iter,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "rf_opt = BayesSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_space,\n",
    "    n_iter=n_iter,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "xgb_opt = BayesSearchCV(\n",
    "    xgboost.XGBClassifier(random_state=42),\n",
    "    xgb_space,\n",
    "    n_iter=n_iter,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "cb_opt = BayesSearchCV(\n",
    "    CatBoostClassifier(random_seed=42, logging_level='Silent'),\n",
    "    cb_space,\n",
    "    n_iter=n_iter,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "# shuffle the data\n",
    "phone_shake_data = phone_shake_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "num_train_rows = int(0.7*phone_shake_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:44:56.730819Z",
     "start_time": "2020-05-31T19:44:52.103944Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:933: FutureWarning: Passing attributes to check_is_fitted is deprecated and will be removed in 0.23. The attributes argument is ignored.\n",
      "  \"argument is ignored.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 after model tuning:  0.9860765690786253\n"
     ]
    }
   ],
   "source": [
    "# executes bayesian optimization\n",
    "_ = lr_opt.fit(phone_shake_data.loc[0:num_train_rows,numeric_cols], phone_shake_data.loc[0:num_train_rows, 'label'])\n",
    "print(\"Logistic Regression F1 after model tuning: \", lr_opt.score(phone_shake_data.loc[num_train_rows:,numeric_cols], phone_shake_data.loc[num_train_rows:, 'label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T19:49:05.449696Z",
     "start_time": "2020-05-31T19:44:56.735128Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:933: FutureWarning: Passing attributes to check_is_fitted is deprecated and will be removed in 0.23. The attributes argument is ignored.\n",
      "  \"argument is ignored.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1 after model tuning:  0.9867734687896846\n"
     ]
    }
   ],
   "source": [
    "# executes bayesian optimization\n",
    "_ = rf_opt.fit(phone_shake_data.loc[0:num_train_rows,numeric_cols], phone_shake_data.loc[0:num_train_rows, 'label'])\n",
    "print(\"Random Forest F1 after model tuning: \", rf_opt.score(phone_shake_data.loc[num_train_rows:,numeric_cols], phone_shake_data.loc[num_train_rows:, 'label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T20:00:37.511048Z",
     "start_time": "2020-05-31T19:49:05.451962Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:933: FutureWarning: Passing attributes to check_is_fitted is deprecated and will be removed in 0.23. The attributes argument is ignored.\n",
      "  \"argument is ignored.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1 after model tuning:  0.9874440869496979\n"
     ]
    }
   ],
   "source": [
    "# executes bayesian optimization\n",
    "_ = xgb_opt.fit(phone_shake_data.loc[0:num_train_rows,numeric_cols], phone_shake_data.loc[0:num_train_rows, 'label'])\n",
    "print(\"XGBoost F1 after model tuning: \", xgb_opt.score(phone_shake_data.loc[num_train_rows:,numeric_cols], phone_shake_data.loc[num_train_rows:, 'label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-31T21:05:37.891Z"
    },
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# executes bayesian optimization\n",
    "_ = cb_opt.fit(phone_shake_data[numeric_cols], phone_shake_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T20:59:21.760278Z",
     "start_time": "2020-05-31T20:59:21.727903Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost F1 after model tuning:  0.9952979598260835\n"
     ]
    }
   ],
   "source": [
    "print(\"CatBoost F1 after model tuning: \", cb_opt.score(phone_shake_data.loc[num_train_rows:,numeric_cols], phone_shake_data.loc[num_train_rows:, 'label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A few insights from the exercise\n",
    "- outliers in this scenario are not to be discarded but need to be valued \n",
    "- the overall acceleration and angular velocity are useful features too\n",
    "- oversampling the data using SMOTE, ADASYN, etc doesn't really make a lot of impact\n",
    "- CatBoost and XGBoost have been the better performing model with Logistic coming in close\n",
    "- Model tuning with just a few iterations gives vast a improvement in F1 scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
